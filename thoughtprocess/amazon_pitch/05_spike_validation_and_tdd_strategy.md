# Phase 1 Validation & TDD Strategy: `manim-devops`

## Explanation
The `Execution Roadmap` defined three pure-Python Proof of Concept (PoC) Spikes to validate the highest-risk technical assumptions of the `manim-devops` pipeline before architecting a formal library. We have now fully implemented and run these spikes. All 14 test cases pass across the board.

The successful execution of these spikes mathematically proves our core hypothesis: we can ingest a broken web SVG, construct an abstract graph topology, generate scaled Cartesian coordinates purely in Python (avoiding C-bindings like `pygraphviz`), and mathematically route 90-degree orthogonal edges between the exact bounding boxes of the scaled nodes.

Having proven the granular mechanics, the project must immediately shift to rigorous Test-Driven Development (TDD) to construct the integration layer (Phase 2). We will not guess if the architecture works; we will write the AWS 3-Tier Web App blueprint as a failing test fixture, and we will write the absolute minimum code required in the `manim_devops` package to make it pass.

---

## 3 Why's (Validating the Spikes)

1. **Why did Spike 1 (SVG Sanitization) succeed where raw Manim failed?**
   Raw Manim (`SVGMobject`) relies on an XML parser that crashes upon encountering generic `<style>` blocks or embedded CSS classes. By writing a regex pre-processor that crawls the XML, extracts the `.cls-X` CSS dictionaries, inlines them directly as `fill="#HEX"` attributes on the `<path>` tags, and aggressively strips out the `<defs>` and `<style>` nodes, we perfectly neuter the SVG into a purely declarative path format that Manim can safely map to OpenGL curves.
2. **Why was Spike 2 (NetworkX Math) refactored for determinism, and why does it matter?**
   Spike 2 initially constructed the `GraphModel` using Python `set()` collections to track nodes and edges. While mathematically correct, sets are unordered in Python. `NetworkX` uses the insertion order of nodes to seed its layout algorithms. A non-deterministic node order means `NetworkX` would return slightly different `(X, Y)` coordinates every time the script was run. This would instantly bust Manim's hash-based frame caching, forcing the user to wait for a 5-minute FFmpeg re-render every time they ran the script, even if nothing changed. Converting the sets to ordered `list()` structures guarantees 100% deterministic layout calculation.
3. **Why did Spike 3 (Edge Anchoring) project off the exact radius?**
   Cartesian coordinates generated by layout engines pinpoint the exact *center* of a node. If you draw a line from `Center A` to `Center B`, the line visually slices through the icon stroke, making the diagram look amateurish. By defining a mathematical boundary box based on the Manim Mobject's radius, we can project a unit vector outward from the center, stopping at the exact pixel where the icon ends. This allows our orthogonal router to start drawing an "L-bend" precisely off the boundary edge without rendering on top of the node body.

---

## 3 Deep Technical Questions (The TDD Phase)

1. **The Abstract Syntax Tree (AST) vs The Mobjects:** How strictly do we separate the `Topology` math models from the `DevopsScene` rendering models? Should a `CloudNode` natively know how to draw itself, or should it just be a dumb dataclass holding X/Y coordinates until the `Scene` parses it?
2. **The "Tick" Cycle in Manim:** TDD allows us to assert static state, but animations in Manim happen over time. How do we write a test that asserts an orthogonal line correctly routes *around* an obstacle that is currently in motion during a `.Transform()` animation?
3. **API Ergonomics vs Setup Boilerplate:** The core goal is frictionless onboarding. If a user has to manually instantiate a `Topology`, an `OrthogonalRouter`, an `SVGSanitizer`, and a `LayoutEngine` just to draw a generic EC2 instance, the API has failed. How do we use TDD to force the minimal amount of lines in a user-facing script?

---

## Self-Reflection
Writing throwaway spike code is incredibly freeing. There is no consequence to failure. But translating those spikes into a production-grade library wrapper is the moment projects usually stall due to "analysis paralysis" over architecture and clean code boundaries. 

This is exactly why strict TDD is the only acceptable path forward. If we write a test that simply asserts: `assert len(topology.nodes) == 7`, we do not have to argue about metaclasses or complex inheritance trees. We just write the shortest, ugliest code possible to make the test pass. The AWS 3-Tier Web App fixture is not just a test; it is the absolute definition of `v0.1.0` feature completion. Until the math underlying that specific diagram executes cleanly, we are not allowed to worry about colors, gradients, or glowing animation packets.

---

## The Strict TDD Protocol (Execution Blueprint)

1.  **Red (The Contract):** Execute the existing `pytest tests/test_architecture_layout.py`. It will fail because `manim_devops.core.Topology` does not exist or raises `NotImplementedError`.
2.  **Green (The Implementation):** Scaffold `manim_devops/core.py`. Copy the pure Python `NetworkX` layout math from Spike 2 directly into the `Topology` interface. 
3.  **Refactor (The Integration):** Hook `CloudNode` instances into the `Topology` internal array. Ensure the `calculate_layout()` method successfully maps every AWS node in the fixture to a valid `(X, Y, 0.0)` Cartesian coordinate array.
4.  **Repeat:** Once the force-directed math is proven, apply TDD to the `OrthogonalRouter` and the SVG parsing until the entire AWS 3-Tier topology can be generated visually.

---

## ðŸ›‘ The Total Coverage & Immutable Test Imperative

In addition to the Red-Green-Refactor cycle, `manim-devops` enforces two unyielding testing mandates to prevent regressions:

### 1. 100% Test Coverage Requirement
Every line of code committed to the `manim_devops` module must be covered by an automated test. 
*   **The Check:** We will continuously execute `python -m pytest --cov=manim_devops`. 
*   **The Protocol:** If a coverage gap is detected, execution **must immediately halt**. We will identify the specific business logic missing coverage, write the failing test for it, achieve a pass state, and explicitly confirm with the User before proceeding to any new feature development.

### 2. The Immutable Test Policy
A passing test is a permanent business contract. Once a test is written and confirmed by the User to accurately reflect the desired behavior (e.g., "The Orthogonal router returns exactly 3 waypoints for a generic L-bend"), that test becomes **Immutable**.
*   **Modification Ban:** A developer is *never* allowed to modify a passing test just to make new code pass. 
*   **Exception:** An immutable test may only be altered if the overarching User business requirements fundamentally change, requiring an explicit, documented agreement to rewrite the contract.
